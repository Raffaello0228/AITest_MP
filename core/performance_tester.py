#!/usr/bin/env python3
"""
æ€§èƒ½æµ‹è¯•æ¨¡å—
æä¾›åˆ†æ‰¹æ¬¡æ€§èƒ½æµ‹è¯•åŠŸèƒ½ï¼Œç”¨äºæµ‹è¯• brief-save å’Œ brief-submit-query æ¥å£çš„æ€§èƒ½è¡¨ç°
"""

import asyncio
import json
import statistics
import time
from dataclasses import dataclass, asdict
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any

from core.api_client import APIClient, create_client_from_config
from core.api_config import (
    get_api_config,
    get_strategy_config,
    LOGGING_CONFIG,
    CONCURRENCY_CONFIG,
)


@dataclass
class TaskResult:
    """ä»»åŠ¡ç»“æœ"""

    index: int
    job_id: Optional[str]
    save_time: int
    poll_time: int
    poll_attempts: int
    total_time: int
    final_job_status: str
    is_final: bool
    success: bool
    task_status: str = "RUNNING"


@dataclass
class BatchResult:
    """æ‰¹æ¬¡ç»“æœ"""

    concurrency: int
    timestamp: str
    batch_time: int
    total_tests: int
    successful_tests: int
    failed_tests: int
    success_rate: float
    failure_rate: float
    performance_metrics: Optional[Dict]
    task_time_details: List[TaskResult]
    config_name: str
    concurrency_stats: Optional[Dict] = None


class APILogger:
    """APIæ¥å£æ—¥å¿—è®°å½•å™¨"""

    def __init__(self):
        self.request_id = 0
        self.active_tasks = 0  # å½“å‰æ´»è·ƒä»»åŠ¡æ•°ï¼ˆEXECUTINGçŠ¶æ€ï¼‰
        self.max_active_tasks = 0  # å†å²æœ€é«˜æ´»è·ƒä»»åŠ¡æ•°
        self.task_start_times = {}  # è®°å½•ä»»åŠ¡å¼€å§‹æ—¶é—´
        self.task_statuses = {}  # è®°å½•ä»»åŠ¡çŠ¶æ€
        self.max_concurrency_threshold = CONCURRENCY_CONFIG.get(
            "max_concurrency_threshold", 16
        )

    def get_next_request_id(self) -> int:
        """è·å–ä¸‹ä¸€ä¸ªè¯·æ±‚ID"""
        self.request_id += 1
        return self.request_id

    def task_started(self, task_index: int):
        """ä»»åŠ¡å¼€å§‹æ‰§è¡Œ"""
        self.task_start_times[task_index] = time.time()
        self.task_statuses[task_index] = "STARTED"

    def update_task_status(self, task_index: int, job_status: str):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        previous_status = self.task_statuses.get(task_index, "UNKNOWN")
        self.task_statuses[task_index] = job_status

        # å¦‚æœçŠ¶æ€å˜ä¸ºEXECUTINGï¼Œå¢åŠ æ´»è·ƒä»»åŠ¡æ•°
        if job_status == "EXECUTING" and previous_status != "EXECUTING":
            self.active_tasks += 1
            if self.active_tasks > self.max_active_tasks:
                self.max_active_tasks = self.active_tasks

            if self.active_tasks > self.max_concurrency_threshold:
                print(
                    f"[CONCURRENCY-ALERT] å½“å‰æ´»è·ƒä»»åŠ¡æ•° {self.active_tasks} è¶…è¿‡é˜ˆå€¼ {self.max_concurrency_threshold}ï¼"
                )

        # å¦‚æœçŠ¶æ€ä»EXECUTINGå˜ä¸ºå…¶ä»–çŠ¶æ€ï¼Œå‡å°‘æ´»è·ƒä»»åŠ¡æ•°
        elif previous_status == "EXECUTING" and job_status != "EXECUTING":
            self.active_tasks = max(0, self.active_tasks - 1)

    def task_completed(self, task_index: int):
        """ä»»åŠ¡å®Œæˆæ‰§è¡Œ"""
        if task_index in self.task_start_times:
            del self.task_start_times[task_index]

        if self.task_statuses.get(task_index) == "EXECUTING":
            self.active_tasks = max(0, self.active_tasks - 1)

        if task_index in self.task_statuses:
            del self.task_statuses[task_index]

    def get_concurrency_stats(self) -> Dict:
        """è·å–å¹¶å‘ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "current_active_tasks": self.active_tasks,
            "max_active_tasks": self.max_active_tasks,
            "active_task_count": len(self.task_start_times),
        }

    def reset_concurrency_stats(self):
        """é‡ç½®å¹¶å‘ç»Ÿè®¡"""
        self.active_tasks = 0
        self.max_active_tasks = 0
        self.task_start_times.clear()
        self.task_statuses.clear()


class PerformanceTester:
    """æ€§èƒ½æµ‹è¯•å™¨"""

    def __init__(
        self,
        api_config: Dict[str, Any],
        strategy_config=None,
        request_json_path: Optional[str] = None,
        default_request_body: Optional[Dict] = None,
    ):
        """
        åˆå§‹åŒ–æ€§èƒ½æµ‹è¯•å™¨

        Args:
            api_config: APIé…ç½®å­—å…¸
            strategy_config: ç­–ç•¥é…ç½®ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
            request_json_path: request.jsonæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            default_request_body: é»˜è®¤è¯·æ±‚ä½“ï¼ˆå¯é€‰ï¼‰
        """
        self.api_config = api_config
        self.strategy = strategy_config or get_strategy_config()
        self.request_json_path = request_json_path
        self.default_request_body = default_request_body
        self.client: Optional[APIClient] = None
        self.api_logger = APILogger()

    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        self.client = create_client_from_config(
            api_config=self.api_config,
            request_json_path=self.request_json_path,
            default_request_body=self.default_request_body,
        )
        await self.client.__aenter__()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        if self.client:
            await self.client.__aexit__(exc_type, exc_val, exc_tb)

    async def fetch_one_uuid(self) -> str:
        """è·å–ä¸€ä¸ªUUID"""
        if not self.client:
            raise RuntimeError("Client not initialized")
        return await self.client.fetch_uuid()

    async def run_complete_test(
        self, uuid: str, index: int, request_body: Optional[Dict] = None
    ) -> TaskResult:
        """å®Œæ•´çš„æµ‹è¯•æµç¨‹ï¼šsave + è½®è¯¢"""
        self.api_logger.task_started(index)

        try:
            # 1. è°ƒç”¨brief-saveæ¥å£
            save_start = time.time()
            save_result = await self.client.save_task(uuid, request_body)
            save_time = int((time.time() - save_start) * 1000)

            if not save_result["ok"]:
                self.api_logger.task_completed(index)
                return TaskResult(
                    index=index,
                    job_id=None,
                    save_time=save_time,
                    poll_time=0,
                    poll_attempts=0,
                    total_time=save_time,
                    final_job_status="SAVE_FAILED",
                    is_final=True,
                    success=False,
                    task_status="FAILED",
                )

            job_id = save_result.get("job_id")

            # 2. è½®è¯¢brief-submit-queryæ¥å£
            poll_start = time.time()
            poll_result = await self._poll_job_status_with_monitoring(
                uuid, index, job_id
            )
            poll_time = int((time.time() - poll_start) * 1000)

            self.api_logger.task_completed(index)

            return TaskResult(
                index=index,
                job_id=job_id,
                save_time=save_time,
                poll_time=poll_time,
                poll_attempts=poll_result.get("attempts", 0),
                total_time=save_time + poll_time,
                final_job_status=poll_result.get("job_status", "UNKNOWN"),
                is_final=poll_result.get("is_final", True),
                success=poll_result.get("success", False),
                task_status="COMPLETED",
            )
        except Exception as e:
            self.api_logger.task_completed(index)
            raise

    async def _poll_job_status_with_monitoring(
        self, uuid: str, index: int, job_id: Optional[str]
    ) -> Dict[str, Any]:
        """è½®è¯¢ä»»åŠ¡çŠ¶æ€ï¼ˆå¸¦å¹¶å‘ç›‘æ§ï¼‰"""
        if not uuid:
            return {
                "success": False,
                "error": "No UUID provided",
                "index": index,
                "is_final": True,
                "attempts": 0,
            }

        # ä½¿ç”¨ api_client çš„ query_job_status æ–¹æ³•ï¼Œä½†éœ€è¦ç›‘æ§çŠ¶æ€
        # ç”±äºéœ€è¦ç›‘æ§å¹¶å‘çŠ¶æ€ï¼Œæˆ‘ä»¬éœ€è¦è‡ªå®šä¹‰è½®è¯¢é€»è¾‘
        query_url = self.api_config["QUERY_URL_TEMPLATE"].format(job_id=uuid)
        start_time = time.time()

        for attempt in range(1, self.strategy.max_polling_attempts + 1):
            try:
                if not self.client.session:
                    raise RuntimeError("Client session not initialized")
                # æ³¨æ„ï¼šæ ¹æ® api_client.pyï¼Œè¿™é‡Œåº”è¯¥ä½¿ç”¨ POST è¯·æ±‚
                async with self.client.session.post(
                    query_url, headers=self.api_config["COMMON_HEADERS"]
                ) as response:
                    if response.status >= 400:
                        raise Exception(f"HTTP {response.status}: {response.reason}")

                    response_text = await response.text()
                    data = json.loads(response_text) if response_text else {}
                    job_status = data.get("result", {}).get("jobStatus") or data.get(
                        "jobStatus"
                    )
                    actual_job_id = data.get("result", {}).get("jobId") or job_id

                    # æ›´æ–°ä»»åŠ¡çŠ¶æ€ï¼ˆç”¨äºå¹¶å‘ç›‘æ§ï¼‰
                    if job_status:
                        self.api_logger.update_task_status(index, job_status)

                    # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€ - åªæœ‰SUCCESSã€FAILEDã€ERRORæ‰è§†ä¸ºæœ€ç»ˆçŠ¶æ€
                    if job_status in ["SUCCESS", "FAILED", "ERROR"]:
                        total_time = int((time.time() - start_time) * 1000)
                        return {
                            "success": job_status == "SUCCESS",
                            "job_status": job_status,
                            "attempts": attempt,
                            "total_time": total_time,
                            "index": index,
                            "job_id": actual_job_id,
                            "is_final": True,
                            "error": (
                                f"Job failed with status: {job_status}"
                                if job_status != "SUCCESS"
                                else None
                            ),
                        }

                    # å¦‚æœè¿˜åœ¨å¤„ç†ä¸­ï¼Œç­‰å¾…åç»§ç»­è½®è¯¢
                    if attempt < self.strategy.max_polling_attempts:
                        await asyncio.sleep(self.strategy.polling_interval / 1000)

            except Exception as error:
                if attempt < self.strategy.max_polling_attempts:
                    await asyncio.sleep(self.strategy.polling_interval / 1000)

        # è¶…è¿‡æœ€å¤§è½®è¯¢æ¬¡æ•° - è§†ä¸ºæœ€ç»ˆçŠ¶æ€
        total_time = int((time.time() - start_time) * 1000)
        return {
            "success": False,
            "attempts": self.strategy.max_polling_attempts,
            "total_time": total_time,
            "index": index,
            "job_id": job_id,
            "error": f"Timeout after {self.strategy.max_polling_attempts} attempts",
            "is_final": True,
        }

    async def run_concurrency_level(
        self, concurrency: int, request_bodies: Optional[List[Dict]] = None
    ) -> Optional[BatchResult]:
        """è¿è¡Œå•ä¸ªå¹¶å‘çº§åˆ«çš„æµ‹è¯•"""
        # é‡ç½®å¹¶å‘ç»Ÿè®¡
        self.api_logger.reset_concurrency_stats()

        print(f"\n=== å¼€å§‹æµ‹è¯•å¹¶å‘çº§åˆ«: {concurrency} ===")
        print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 50)

        batch_start = time.time()

        try:
            # 1. å¹¶å‘è·å–UUID
            print("\n1. è·å–UUID...")
            t1 = time.time()

            uuid_tasks = [self.fetch_one_uuid() for _ in range(concurrency)]
            uuid_results = await asyncio.gather(*uuid_tasks, return_exceptions=True)

            ok_uuids = []
            uuid_failed = []

            for i, result in enumerate(uuid_results):
                if isinstance(result, Exception):
                    uuid_failed.append({"index": i, "error": str(result)})
                else:
                    ok_uuids.append(result)

            print(
                f"UUIDè·å–ç»“æœ -> æˆåŠŸ: {len(ok_uuids)}, å¤±è´¥: {len(uuid_failed)}, è€—æ—¶: {int((time.time() - t1) * 1000)}ms"
            )

            if not ok_uuids:
                print("æ²¡æœ‰è·å–åˆ°UUIDï¼Œæµ‹è¯•ç»ˆæ­¢ã€‚")
                return None

            # 2. å¹¶å‘æ‰§è¡Œå®Œæ•´çš„æµ‹è¯•æµç¨‹
            print("\n2. æ‰§è¡Œå®Œæ•´æµ‹è¯•æµç¨‹...")
            t2 = time.time()

            # å‡†å¤‡è¯·æ±‚ä½“åˆ—è¡¨
            if request_bodies is None:
                request_bodies = [None] * len(ok_uuids)
            elif len(request_bodies) < len(ok_uuids):
                # å¦‚æœè¯·æ±‚ä½“æ•°é‡ä¸è¶³ï¼Œç”¨Noneå¡«å……
                request_bodies.extend([None] * (len(ok_uuids) - len(request_bodies)))

            test_tasks = [
                self.run_complete_test(uuid, i, request_bodies[i])
                for i, uuid in enumerate(ok_uuids)
            ]
            test_results = await asyncio.gather(*test_tasks, return_exceptions=True)

            t3 = time.time()

            # 3. åˆ†æç»“æœ
            print("\n3. åˆ†ææµ‹è¯•ç»“æœ...")
            successes = []
            failures = []

            for result in test_results:
                if isinstance(result, Exception):
                    failures.append({"error": str(result)})
                elif result.success:
                    successes.append(result)
                else:
                    failures.append(result)

            # 4. è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            batch_time = int((t3 - batch_start) * 1000)
            success_rate = len(successes) / len(ok_uuids) if ok_uuids else 0
            failure_rate = len(failures) / len(ok_uuids) if ok_uuids else 0

            performance_metrics = None
            task_time_details = []

            if successes:
                save_times = [s.save_time for s in successes]
                poll_times = [s.poll_time for s in successes]
                total_times = [s.total_time for s in successes]
                poll_attempts = [s.poll_attempts for s in successes]

                performance_metrics = {
                    "save": {
                        "avg": int(statistics.mean(save_times)),
                        "min": min(save_times),
                        "max": max(save_times),
                    },
                    "poll": {
                        "avg_attempts": int(statistics.mean(poll_attempts)),
                        "avg_time": int(statistics.mean(poll_times)),
                        "min_time": min(poll_times),
                        "max_time": max(poll_times),
                    },
                    "total": {
                        "avg": int(statistics.mean(total_times)),
                        "min": min(total_times),
                        "max": max(total_times),
                    },
                }

                task_time_details = sorted(successes, key=lambda x: x.total_time)

            # 5. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            concurrency_stats = self.api_logger.get_concurrency_stats()

            print(f"\n=== å¹¶å‘çº§åˆ« {concurrency} æµ‹è¯•ç»“æœ ===")
            print(f"æ‰¹æ¬¡æ€»æ—¶é—´: {batch_time}ms")
            print(f"æµ‹è¯•æ•°é‡: {len(ok_uuids)}")
            print(f"å®Œæ•´æˆåŠŸ: {len(successes)}")
            print(f"éƒ¨åˆ†å¤±è´¥: {len(failures)}")
            print(f"æˆåŠŸç‡: {success_rate * 100:.2f}%")
            print(f"å¤±è´¥ç‡: {failure_rate * 100:.2f}%")
            print(f"æœ€é«˜å¹¶å‘ä»»åŠ¡æ•°: {concurrency_stats['max_active_tasks']}")
            print(f"å½“å‰æ´»è·ƒä»»åŠ¡æ•°: {concurrency_stats['current_active_tasks']}")

            if performance_metrics:
                print(f"\n--- Saveæ¥å£æ€§èƒ½ ---")
                print(f"å¹³å‡è€—æ—¶: {performance_metrics['save']['avg']}ms")
                print(f"æœ€å°è€—æ—¶: {performance_metrics['save']['min']}ms")
                print(f"æœ€å¤§è€—æ—¶: {performance_metrics['save']['max']}ms")

                print(f"\n--- è½®è¯¢æ€§èƒ½ ---")
                print(f"å¹³å‡è½®è¯¢æ¬¡æ•°: {performance_metrics['poll']['avg_attempts']}")
                print(f"å¹³å‡è½®è¯¢æ€»æ—¶é—´: {performance_metrics['poll']['avg_time']}ms")
                print(
                    f"è½®è¯¢æ—¶é—´èŒƒå›´: {performance_metrics['poll']['min_time']}ms - {performance_metrics['poll']['max_time']}ms"
                )

                print(f"\n--- æ€»ä½“æ€§èƒ½ ---")
                print(f"å¹³å‡æ€»è€—æ—¶: {performance_metrics['total']['avg']}ms")
                print(
                    f"æ€»è€—æ—¶èŒƒå›´: {performance_metrics['total']['min']}ms - {performance_metrics['total']['max']}ms"
                )

            # 6. è¿”å›æ‰¹æ¬¡ç»“æœ
            return BatchResult(
                concurrency=concurrency,
                timestamp=datetime.now().isoformat(),
                batch_time=batch_time,
                total_tests=len(ok_uuids),
                successful_tests=len(successes),
                failed_tests=len(failures),
                success_rate=success_rate,
                failure_rate=failure_rate,
                performance_metrics=performance_metrics,
                task_time_details=task_time_details,
                config_name=self.strategy.name,
                concurrency_stats=concurrency_stats,
            )

        except Exception as error:
            print(f"å¹¶å‘çº§åˆ« {concurrency} æµ‹è¯•å¤±è´¥: {str(error)}")
            concurrency_stats = self.api_logger.get_concurrency_stats()
            return BatchResult(
                concurrency=concurrency,
                timestamp=datetime.now().isoformat(),
                batch_time=int((time.time() - batch_start) * 1000),
                total_tests=0,
                successful_tests=0,
                failed_tests=0,
                success_rate=0.0,
                failure_rate=1.0,
                performance_metrics=None,
                task_time_details=[],
                config_name=self.strategy.name,
                concurrency_stats=concurrency_stats,
            )

    async def run_strategy_test(
        self, request_bodies: Optional[List[Dict]] = None
    ) -> Dict[str, Any]:
        """æ‰§è¡Œåˆ†æ‰¹æ¬¡æ€§èƒ½æµ‹è¯•ç­–ç•¥"""
        print("=== åˆ†æ‰¹æ¬¡æ€§èƒ½æµ‹è¯•ç­–ç•¥å¼€å§‹ ===")
        print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"æµ‹è¯•ç­–ç•¥: {self.strategy.name}")
        print(
            f"æµ‹è¯•ç­–ç•¥: ä»¥{self.strategy.step_size}ä¸ºæ­¥é•¿ï¼Œä»{self.strategy.start_concurrency}åˆ°{self.strategy.max_concurrency}å¹¶å‘"
        )
        print(f"æ‰¹æ¬¡é—´å»¶è¿Ÿ: {self.strategy.batch_delay}ms")
        print(f"æˆåŠŸç‡é˜ˆå€¼: {self.strategy.success_rate_threshold * 100:.1f}%")
        print(f"å¤±è´¥ç‡é˜ˆå€¼: {self.strategy.max_failure_rate * 100:.1f}%")
        print("=" * 50)

        overall_start = time.time()
        all_results = []
        should_continue = True

        # æŒ‰æ­¥é•¿é€æ­¥å¢åŠ å¹¶å‘æ•°
        for concurrency in range(
            self.strategy.start_concurrency,
            self.strategy.max_concurrency + 1,
            self.strategy.step_size,
        ):
            if not should_continue:
                break

            print(f"\nğŸš€ å‡†å¤‡æµ‹è¯•å¹¶å‘çº§åˆ«: {concurrency}")

            # æ‰§è¡Œå½“å‰å¹¶å‘çº§åˆ«çš„æµ‹è¯•
            batch_result = await self.run_concurrency_level(concurrency, request_bodies)

            if batch_result:
                all_results.append(batch_result)

                # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»§ç»­æµ‹è¯•
                if batch_result.success_rate < self.strategy.success_rate_threshold:
                    print(
                        f"\nâš ï¸  æˆåŠŸç‡ {batch_result.success_rate * 100:.1f}% ä½äºé˜ˆå€¼ {self.strategy.success_rate_threshold * 100:.1f}%ï¼Œåœæ­¢æµ‹è¯•"
                    )
                    should_continue = False
                elif batch_result.failure_rate > self.strategy.max_failure_rate:
                    print(
                        f"\nâš ï¸  å¤±è´¥ç‡ {batch_result.failure_rate * 100:.1f}% é«˜äºé˜ˆå€¼ {self.strategy.max_failure_rate * 100:.1f}%ï¼Œåœæ­¢æµ‹è¯•"
                    )
                    should_continue = False

            # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªæ‰¹æ¬¡ï¼Œç­‰å¾…åç»§ç»­
            if (
                should_continue
                and concurrency + self.strategy.step_size
                <= self.strategy.max_concurrency
            ):
                print(f"\nâ³ ç­‰å¾… {self.strategy.batch_delay}ms åå¼€å§‹ä¸‹ä¸€ä¸ªæ‰¹æ¬¡...")
                await asyncio.sleep(self.strategy.batch_delay / 1000)

        # ä¿å­˜æ‰€æœ‰ç»“æœ
        complete_results = {
            "timestamp": datetime.now().isoformat(),
            "strategy": self.strategy.name,
            "config": {
                "strategy": asdict(self.strategy),
            },
            "overall_time": int((time.time() - overall_start) * 1000),
            "batches": [asdict(r) for r in all_results],
            "summary": {
                "total_batches": len(all_results),
                "total_tests": sum(r.total_tests for r in all_results),
                "total_successful_tests": sum(r.successful_tests for r in all_results),
                "total_failed_tests": sum(r.failed_tests for r in all_results),
                "max_concurrency_tested": (
                    max(r.concurrency for r in all_results) if all_results else 0
                ),
                "average_success_rate": (
                    sum(r.success_rate for r in all_results) / len(all_results)
                    if all_results
                    else 0
                ),
                "average_failure_rate": (
                    sum(r.failure_rate for r in all_results) / len(all_results)
                    if all_results
                    else 0
                ),
            },
        }

        print(f"\n=== æ€»ä½“æµ‹è¯•ç»Ÿè®¡ ===")
        print(f"æ€»æµ‹è¯•æ—¶é—´: {complete_results['overall_time']}ms")
        print(f"æµ‹è¯•æ‰¹æ¬¡æ•°: {complete_results['summary']['total_batches']}")
        print(f"æ€»æµ‹è¯•æ•°: {complete_results['summary']['total_tests']}")
        print(f"æ€»æˆåŠŸæ•°: {complete_results['summary']['total_successful_tests']}")
        print(f"æ€»å¤±è´¥æ•°: {complete_results['summary']['total_failed_tests']}")
        print(
            f"æœ€å¤§æµ‹è¯•å¹¶å‘æ•°: {complete_results['summary']['max_concurrency_tested']}"
        )
        print(
            f"å¹³å‡æˆåŠŸç‡: {complete_results['summary']['average_success_rate'] * 100:.2f}%"
        )
        print(
            f"å¹³å‡å¤±è´¥ç‡: {complete_results['summary']['average_failure_rate'] * 100:.2f}%"
        )

        print(f"\n=== åˆ†æ‰¹æ¬¡æ€§èƒ½æµ‹è¯•ç­–ç•¥å®Œæˆ ===")

        return complete_results
